{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fc8311-f70e-4509-8dde-a66c392b26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b8ba1-a9e5-495b-9c5f-ff9a6af097b6",
   "metadata": {},
   "source": [
    "# 0 Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285e766-708d-48fb-9b29-331cac165529",
   "metadata": {},
   "source": [
    "## 0.1 Transform data into BOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daccec79-a89b-42c4-9bac-4c4ca3c79cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory path for each enron subdirectory in project1_datasets\n",
    "dir_train_paths = {\n",
    "    \"enron1_path\": [Path(\"project1_datasets/enron1_train/ham\"),Path(\"project1_datasets/enron1_train/spam\")],\n",
    "    \"enron2_path\": [Path(\"project1_datasets/enron2_train/ham\"),Path(\"project1_datasets/enron2_train/spam\")],\n",
    "    \"enron4_path\": [Path(\"project1_datasets/enron4_train/ham\"),Path(\"project1_datasets/enron4_train/spam\")]\n",
    "}\n",
    "dir_test_paths = {\n",
    "    \"enron1_path\": [Path(\"project1_datasets/enron1_test/ham\"),Path(\"project1_datasets/enron1_test/spam\")],\n",
    "    \"enron2_path\": [Path(\"project1_datasets/enron2_test/ham\"),Path(\"project1_datasets/enron2_test/spam\")],\n",
    "    \"enron4_path\": [Path(\"project1_datasets/enron4_test/ham\"),Path(\"project1_datasets/enron4_test/spam\")]\n",
    "}\n",
    "dir_path = Path(\"project1_datasets/enron1_train/ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c7ccad-3ee2-4167-a4a7-6245003b89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that reads files in a directory, and turns its content to a string that is appeneded to a list\n",
    "def create_texts(path_list):\n",
    "    ham = False\n",
    "    texts = []\n",
    "    y = []\n",
    "    count_map = {\n",
    "        path_list[0]: 0,\n",
    "        path_list[1]: 0\n",
    "    }\n",
    "    \n",
    "    for dir_path in path_list:\n",
    "        if not ham:\n",
    "            ham = True\n",
    "        else:\n",
    "            ham = False\n",
    "        for filename in os.listdir(dir_path):\n",
    "             if filename.endswith(\".txt\"):\n",
    "                file_path = os.path.join(dir_path, filename)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "                    count_map[dir_path] = count_map.get(dir_path, 0) + 1\n",
    "                    texts.append(file.read())\n",
    "                    if ham == True:\n",
    "                        y.append(0)\n",
    "                    else:\n",
    "                        y.append(1)\n",
    "\n",
    "    for k, v in count_map.items():\n",
    "        print(f\"In {k} there are {v} files\")\n",
    "    return texts, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ce6a6b-5bef-4887-936d-a57c892a2493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In project1_datasets/enron1_train/ham there are 319 files\n",
      "In project1_datasets/enron1_train/spam there are 131 files\n",
      "In project1_datasets/enron2_train/ham there are 340 files\n",
      "In project1_datasets/enron2_train/spam there are 123 files\n",
      "In project1_datasets/enron4_train/ham there are 133 files\n",
      "In project1_datasets/enron4_train/spam there are 402 files\n"
     ]
    }
   ],
   "source": [
    "# Turn train txt files into array of strings, and get the correct classification of each email in the enron_train_y variables\n",
    "enron1_train_texts, enron1_train_y = create_texts(dir_train_paths[\"enron1_path\"])\n",
    "enron2_train_texts, enron2_train_y = create_texts(dir_train_paths[\"enron2_path\"])\n",
    "enron4_train_texts, enron4_train_y = create_texts(dir_train_paths[\"enron4_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3482afe-e8ce-4387-9f07-f9aa2d35c0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In project1_datasets/enron1_test/ham there are 307 files\n",
      "In project1_datasets/enron1_test/spam there are 149 files\n",
      "In project1_datasets/enron2_test/ham there are 348 files\n",
      "In project1_datasets/enron2_test/spam there are 130 files\n",
      "In project1_datasets/enron4_test/ham there are 152 files\n",
      "In project1_datasets/enron4_test/spam there are 391 files\n"
     ]
    }
   ],
   "source": [
    "# Turn test txt files into array of strings, and get the correct classification of each email in the enron_test_y variables\n",
    "enron1_test_texts, enron1_test_y = create_texts(dir_test_paths[\"enron1_path\"])\n",
    "enron2_test_texts, enron2_test_y = create_texts(dir_test_paths[\"enron2_path\"])\n",
    "enron4_test_texts, enron4_test_y = create_texts(dir_test_paths[\"enron4_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c471a44c-04af-4535-b5b9-ea7b0d187ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that turns array of strings into BOW model\n",
    "def create_BOW_model(texts, vocabulary=None, using_vocab=False):\n",
    "    if using_vocab:\n",
    "            vectorizer = feature_extraction.text.CountVectorizer(stop_words='english', strip_accents='ascii', vocabulary=vocabulary)\n",
    "            X = vectorizer.fit_transform(texts)\n",
    "            bow_model = X.toarray()\n",
    "            return bow_model\n",
    "    vectorizer = feature_extraction.text.CountVectorizer(stop_words='english', strip_accents='ascii', token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    bow_model = X.toarray()\n",
    "    vocabulary = vectorizer.get_feature_names_out()\n",
    "    return bow_model, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf0fb6dc-e9ba-42db-897d-856df21af826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Turn train texts into BOW model\n",
    "enron1_train_bow, enron1_train_vocab = create_BOW_model(enron1_train_texts)\n",
    "enron2_train_bow, enron2_train_vocab = create_BOW_model(enron2_train_texts)\n",
    "enron4_train_bow, enron4_train_vocab = create_BOW_model(enron4_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b44b2de5-a00d-411d-a26a-aecb101f5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn test texts into BOW model\n",
    "enron1_test_bow = create_BOW_model(enron1_test_texts, enron1_train_vocab, using_vocab=True)\n",
    "enron2_test_bow = create_BOW_model(enron2_test_texts, enron2_train_vocab, using_vocab=True)\n",
    "enron4_test_bow = create_BOW_model(enron4_test_texts, enron4_train_vocab, using_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817f5d18-2d13-4b26-8fd2-d66c230d8371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8654 8654\n",
      "8925 8925\n",
      "16334 16334\n"
     ]
    }
   ],
   "source": [
    "print(len(enron1_test_bow[0]), len(enron1_train_bow[0]))\n",
    "print(len(enron2_test_bow[0]), len(enron2_train_bow[0]))\n",
    "print(len(enron4_test_bow[0]), len(enron4_train_bow[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c5f9e-af65-43e3-b244-25d74d5bd20c",
   "metadata": {},
   "source": [
    "## 0.2 Transform data into Bernoulli Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0bf37b1-211a-4494-87e1-24f538f711bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes array and for every value greater than 0, replaces with a 1\n",
    "enron1_train_bn = (enron1_train_bow > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "348ee0f8-f103-43ce-8b35-ea910a1b59b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "2\n",
      "1\n",
      "\n",
      "\n",
      "4\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking to see if it is working as it should\n",
    "for i in range(int(len(enron1_train_bn[0]) / 5)):\n",
    "    if enron1_train_bow[0][i] > 0:\n",
    "        print(enron1_train_bow[0][i])\n",
    "        print(enron1_train_bn[0][i])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d798238-8c2a-4e87-8a43-ce2acbf9f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron2_train_bn = (enron2_train_bow > 0).astype(int)\n",
    "enron4_train_bn = (enron4_train_bow > 0).astype(int)\n",
    "enron1_test_bn = (enron1_test_bow > 0).astype(int)\n",
    "enron2_test_bn = (enron2_test_bow > 0).astype(int)\n",
    "enron4_test_bn = (enron4_test_bow > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e46f9b4-29fc-4379-9476-accd9c1c6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that shuffle elements in multiple arrays around in the exact same way\n",
    "def shuffle(array1, array2, array3):\n",
    "    rng = np.random.default_rng()\n",
    "    state = rng.bit_generator.state\n",
    "    rng.shuffle(array1)\n",
    "    rng.bit_generator.state = state\n",
    "    rng.shuffle(array2)\n",
    "    rng.bit_generator.state = state\n",
    "    rng.shuffle(array3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4da8040-5e6c-49fe-9c57-152cb78e6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle around elements in train set, test set, and correct output\n",
    "shuffle(enron1_train_bow, enron1_train_bn, enron1_train_y)\n",
    "shuffle(enron2_train_bow, enron2_train_bn, enron2_train_y)\n",
    "shuffle(enron4_train_bow, enron4_train_bn, enron4_train_y)\n",
    "shuffle(enron1_test_bow, enron1_test_bn, enron1_test_y)\n",
    "shuffle(enron2_test_bow, enron2_test_bn, enron2_test_y)\n",
    "shuffle(enron4_test_bow, enron4_test_bn, enron4_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c9f40-9821-4993-aa49-2fdbee03fc62",
   "metadata": {},
   "source": [
    "# 1. Multinomial Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cdcf5f-353d-4368-9bac-b76d4530b4a1",
   "metadata": {},
   "source": [
    "## 1.1 Running the algorithm on enron1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a43a73cd-0a24-4ddb-90c9-2ed1ed3a1ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.928\n",
      "The precision score for class 0 is: 0.931, for class 1 is: 0.920\n",
      "The recall score for class 0 is: 0.964, for class 1 is: 0.852\n",
      "The f1 score for class 0 is: 0.947, for class 1 is: 0.885\n"
     ]
    }
   ],
   "source": [
    "# Initialize, train, and predict using enron1\n",
    "\n",
    "# Initialize multinomial Naive Bayes model using sklearn, and set alpha=1.0 for laplace smoothing\n",
    "enron1_multinomialNB = naive_bayes.MultinomialNB(alpha=1.0)\n",
    "\n",
    "# Train model by passing training data and expected values for each email example\n",
    "enron1_multinomialNB.fit(enron1_train_bow, enron1_train_y)\n",
    "\n",
    "# Test model on test data\n",
    "enron1_y_preds = enron1_multinomialNB.predict(enron1_test_bow)\n",
    "\n",
    "# Get metrics using sklearn.metrics\n",
    "MNB_acc_1 = accuracy_score(enron1_test_y, enron1_y_preds)\n",
    "MNB_pre_1 = precision_score(enron1_test_y, enron1_y_preds, average=None)\n",
    "MNB_rec_1 = recall_score(enron1_test_y, enron1_y_preds, average=None)\n",
    "MNB_f1_1 = f1_score(enron1_test_y, enron1_y_preds, average=None)\n",
    "\n",
    "print(f\"The accuracy score is: {MNB_acc_1:.3f}\")\n",
    "print(f\"The precision score for class 0 is: {MNB_pre_1[0]:.3f}, for class 1 is: {MNB_pre_1[1]:.3f}\")\n",
    "print(f\"The recall score for class 0 is: {MNB_rec_1[0]:.3f}, for class 1 is: {MNB_rec_1[1]:.3f}\")\n",
    "print(f\"The f1 score for class 0 is: {MNB_f1_1[0]:.3f}, for class 1 is: {MNB_f1_1[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985e501-de34-4c80-9fb7-012ea2b79569",
   "metadata": {},
   "source": [
    "## 1.2 Running the algorithm on enron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d010f725-1731-4696-8cb8-4a14943a6ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.937\n",
      "The precision score for class 0 is: 0.947, for class 1 is: 0.910\n",
      "The recall score for class 0 is: 0.968, for class 1 is: 0.854\n",
      "The f1 score for class 0 is: 0.957, for class 1 is: 0.881\n"
     ]
    }
   ],
   "source": [
    "# Initialize, train, and predict using enron2\n",
    "enron2_multinomialNB = naive_bayes.MultinomialNB(alpha=1.0)\n",
    "enron2_multinomialNB.fit(enron2_train_bow, enron2_train_y)\n",
    "enron2_y_preds = enron2_multinomialNB.predict(enron2_test_bow)\n",
    "\n",
    "MNB_acc_2 = accuracy_score(enron2_test_y, enron2_y_preds)\n",
    "MNB_pre_2 = precision_score(enron2_test_y, enron2_y_preds, average=None)\n",
    "MNB_rec_2 = recall_score(enron2_test_y, enron2_y_preds, average=None)\n",
    "MNB_f1_2 = f1_score(enron2_test_y, enron2_y_preds, average=None)\n",
    "\n",
    "print(f\"The accuracy score is: {MNB_acc_2:.3f}\")\n",
    "print(f\"The precision score for class 0 is: {MNB_pre_2[0]:.3f}, for class 1 is: {MNB_pre_2[1]:.3f}\")\n",
    "print(f\"The recall score for class 0 is: {MNB_rec_2[0]:.3f}, for class 1 is: {MNB_rec_2[1]:.3f}\")\n",
    "print(f\"The f1 score for class 0 is: {MNB_f1_2[0]:.3f}, for class 1 is: {MNB_f1_2[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed94a6a-9523-4b59-870d-b99eb4bf1d80",
   "metadata": {},
   "source": [
    "## 1.3 Running the algorithm on enron4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "510245dc-236d-4903-ab53-ae0d347763e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.971\n",
      "The precision score for class 0 is: 0.959, for class 1 is: 0.975\n",
      "The recall score for class 0 is: 0.934, for class 1 is: 0.985\n",
      "The f1 score for class 0 is: 0.947, for class 1 is: 0.980\n"
     ]
    }
   ],
   "source": [
    "# Initialize, train, and predict using enron4\n",
    "enron4_multinomialNB = naive_bayes.MultinomialNB(alpha=1.0)\n",
    "enron4_multinomialNB.fit(enron4_train_bow, enron4_train_y)\n",
    "enron4_y_preds = enron4_multinomialNB.predict(enron4_test_bow)\n",
    "\n",
    "MNB_acc_4 = accuracy_score(enron4_test_y, enron4_y_preds)\n",
    "MNB_pre_4 = precision_score(enron4_test_y, enron4_y_preds, average=None)\n",
    "MNB_rec_4 = recall_score(enron4_test_y, enron4_y_preds, average=None)\n",
    "MNB_f1_4 = f1_score(enron4_test_y, enron4_y_preds, average=None)\n",
    "\n",
    "print(f\"The accuracy score is: {MNB_acc_4:.3f}\")\n",
    "print(f\"The precision score for class 0 is: {MNB_pre_4[0]:.3f}, for class 1 is: {MNB_pre_4[1]:.3f}\")\n",
    "print(f\"The recall score for class 0 is: {MNB_rec_4[0]:.3f}, for class 1 is: {MNB_rec_4[1]:.3f}\")\n",
    "print(f\"The f1 score for class 0 is: {MNB_f1_4[0]:.3f}, for class 1 is: {MNB_f1_4[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d78a600-2c8d-49ab-a1e3-7e71c3115bb6",
   "metadata": {},
   "source": [
    "# 2. Discrete Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f40c4d-7944-42de-a94b-eda10e5a7fae",
   "metadata": {},
   "source": [
    "## 2.1 Running the algorithm on enron1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e2b5fb5-85a2-4379-a6c7-2fffef1d311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.730\n",
      "The precision score for class 0 is: 0.931, for class 1 is: 0.906\n",
      "The recall score for class 0 is: 0.990, for class 1 is: 0.195\n",
      "The f1 score for class 0 is: 0.832, for class 1 is: 0.320\n"
     ]
    }
   ],
   "source": [
    "enron1_discreteNB = naive_bayes.BernoulliNB(alpha=1.0)\n",
    "enron1_discreteNB.fit(enron1_train_bn, enron1_train_y)\n",
    "enron1_y_preds = enron1_discreteNB.predict(enron1_test_bn)\n",
    "\n",
    "DNB_acc_1 = accuracy_score(enron1_test_y, enron1_y_preds)\n",
    "DNB_pre_1 = precision_score(enron1_test_y, enron1_y_preds, average=None)\n",
    "DNB_rec_1 = recall_score(enron1_test_y, enron1_y_preds, average=None)\n",
    "DNB_f1_1 = f1_score(enron1_test_y, enron1_y_preds, average=None)\n",
    "\n",
    "print(f\"The accuracy score is: {DNB_acc_1:.3f}\")\n",
    "print(f\"The precision score for class 0 is: {MNB_pre_1[0]:.3f}, for class 1 is: {DNB_pre_1[1]:.3f}\")\n",
    "print(f\"The recall score for class 0 is: {DNB_rec_1[0]:.3f}, for class 1 is: {DNB_rec_1[1]:.3f}\")\n",
    "print(f\"The f1 score for class 0 is: {DNB_f1_1[0]:.3f}, for class 1 is: {DNB_f1_1[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75235443-ec84-410c-8dc7-fa05bdcba470",
   "metadata": {},
   "source": [
    "## 2.2 Running the algorithm on enron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f32ca6e4-5ace-4423-842f-c4eb25ba629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.774\n",
      "The precision score for class 0 is: 0.767, for class 1 is: 0.893\n",
      "The recall score for class 0 is: 0.968, for class 1 is: 0.192\n",
      "The f1 score for class 0 is: 0.865, for class 1 is: 0.316\n"
     ]
    }
   ],
   "source": [
    "enron2_discreteNB = naive_bayes.BernoulliNB(alpha=1.0)\n",
    "enron2_discreteNB.fit(enron2_train_bn, enron2_train_y)\n",
    "enron2_y_preds = enron2_discreteNB.predict(enron2_test_bn)\n",
    "\n",
    "DNB_acc_2 = accuracy_score(enron2_test_y, enron2_y_preds)\n",
    "DNB_pre_2 = precision_score(enron2_test_y, enron2_y_preds, average=None)\n",
    "DNB_rec_2 = recall_score(enron2_test_y, enron2_y_preds, average=None)\n",
    "DNB_f1_2 = f1_score(enron2_test_y, enron2_y_preds, average=None)\n",
    "\n",
    "print(f\"The accuracy score is: {DNB_acc_2:.3f}\")\n",
    "print(f\"The precision score for class 0 is: {DNB_pre_2[0]:.3f}, for class 1 is: {DNB_pre_2[1]:.3f}\")\n",
    "print(f\"The recall score for class 0 is: {MNB_rec_2[0]:.3f}, for class 1 is: {DNB_rec_2[1]:.3f}\")\n",
    "print(f\"The f1 score for class 0 is: {DNB_f1_2[0]:.3f}, for class 1 is: {DNB_f1_2[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c580d8d-c0a0-446b-b940-c8c1ff747222",
   "metadata": {},
   "source": [
    "## 2.3 Running the algorithm on enron4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e362612-555b-47b7-be93-51d2b30b141a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.917\n",
      "The precision score for class 0 is: 1.000, for class 1 is: 0.897\n",
      "The recall score for class 0 is: 0.704, for class 1 is: 1.000\n",
      "The f1 score for class 0 is: 0.826, for class 1 is: 0.946\n"
     ]
    }
   ],
   "source": [
    "enron4_discreteNB = naive_bayes.BernoulliNB(alpha=1.0)\n",
    "enron4_discreteNB.fit(enron4_train_bn, enron4_train_y)\n",
    "enron4_y_preds = enron4_discreteNB.predict(enron4_test_bn)\n",
    "\n",
    "DNB_acc_4 = accuracy_score(enron4_test_y, enron4_y_preds)\n",
    "DNB_pre_4 = precision_score(enron4_test_y, enron4_y_preds, average=None)\n",
    "DNB_rec_4 = recall_score(enron4_test_y, enron4_y_preds, average=None)\n",
    "DNB_f1_4 = f1_score(enron4_test_y, enron4_y_preds, average=None)\n",
    "\n",
    "print(f\"The accuracy score is: {DNB_acc_4:.3f}\")\n",
    "print(f\"The precision score for class 0 is: {DNB_pre_4[0]:.3f}, for class 1 is: {DNB_pre_4[1]:.3f}\")\n",
    "print(f\"The recall score for class 0 is: {DNB_rec_4[0]:.3f}, for class 1 is: {DNB_rec_4[1]:.3f}\")\n",
    "print(f\"The f1 score for class 0 is: {DNB_f1_4[0]:.3f}, for class 1 is: {DNB_f1_4[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9406d1bc-3b54-487e-81a7-26d45e06ad8f",
   "metadata": {},
   "source": [
    "# 3. MCAP Logistic Regression algorithm with L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982fa4c-bfe1-4044-82b5-98cc3b2e777f",
   "metadata": {},
   "source": [
    "## 3.1 Implementation of the MCAP Logistic Regression with L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "40212bb4-b853-4851-b4ca-0989ed00e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "# randomly initialize weights\n",
    "def initialize_weights(n_features):\n",
    "    return np.random.randn(n_features, 1) * 0.01\n",
    "\n",
    "def compute_cost(X, y, weights, lambda_reg):\n",
    "    m = X.shape[0] # number of samples\n",
    "    h = expit(X.dot(weights))\n",
    "    epsilon = 1e-15 # added this because I was getting divide by zero errors when running this algorithm on enron4\n",
    "    cost = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h + epsilon)))\n",
    "    reg_cost = (lambda_reg / (2 * m)) * np.sum(np.square(weights[1:])) # skip bias term\n",
    "    return cost + reg_cost\n",
    "\n",
    "def compute_gradient(X, y, weights, lamda_reg):\n",
    "    m = X.shape[0]\n",
    "    h = expit(X.dot(weights))\n",
    "    gradient = (1 / m) * X.T.dot(h - y)\n",
    "\n",
    "    gradient[1:] += (lamda_reg / m) * weights[1:]\n",
    "    return gradient\n",
    "\n",
    "def gradient_descent(X, y, weights, learning_rate, lamda_reg, num_iterations):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        weights -= learning_rate * compute_gradient(X, y, weights, lambda_reg)\n",
    "        cost = compute_cost(X, y, weights, lamda_reg)\n",
    "        cost_history.append(cost[0][0])\n",
    "\n",
    "    return weights, cost_history\n",
    "\n",
    "# threshold at 0.5 for classification\n",
    "def predict(X, weights):\n",
    "    return expit(X.dot(weights)) >= 0.5\n",
    "\n",
    "def logistic_regression(X_train, y_train, learning_rate, lambda_reg, num_iterations):\n",
    "    n_samples, n_features = X_train.shape\n",
    "    weights = initialize_weights(n_features)\n",
    "    weights, cost_history = gradient_descent(X_train, y_train, weights, learning_rate, lambda_reg, num_iterations)\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34f4af4c-1beb-414e-99fa-ab1ca0a776d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Function to create train and test split\n",
    "\n",
    "def train_test(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5d5a3-4031-494c-8563-4990973b8986",
   "metadata": {},
   "source": [
    "## Running the algorithm on enron1 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49c71295-81fc-4388-8b73-06677fdd21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split enron1 BOW dataset\n",
    "\n",
    "X = enron1_train_bow\n",
    "y = enron1_train_y\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae026d28-e4a7-48b3-a351-6530e91094aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run logistic regression\n",
    "\n",
    "def run_logistic_regression(X_train, y_train, learning_rate, lambda_reg, num_iterations, X_test, y_test):\n",
    "    y_train_LR = np.array(y_train).reshape(-1, 1)\n",
    "\n",
    "    weights, cost_history = logistic_regression(X_train, y_train_LR, learning_rate, lambda_reg, num_iterations)\n",
    "    preds = predict(X_test, weights)\n",
    "    print(f\"Hyperparamters: learning_rate: {learning_rate}, lambda:{lambda_reg}, epochs:{num_iterations} \\nAccuracy: {accuracy_score(y_test, preds):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c392a7f-44db-4758-832d-233723af9c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.1, epochs:500 \n",
      "Accuracy: 0.81\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.83\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.01, epochs:500 \n",
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Run Logistic regression with different lambda values\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "\n",
    "lambda_reg = 0.1\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.01\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b25467b-ce22-48d8-816a-1612825f0a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Selecting lambda = 0.05\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(enron1_train_bow, enron1_train_y, learning_rate, lambda_reg, num_iterations, enron1_test_bow, enron1_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471280c-77bb-4a50-905e-5c87e3349838",
   "metadata": {},
   "source": [
    "## Running the algorithm on enron1 BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4ab678b-4eb3-4f5b-a356-9dc4688a93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enron1_train_bn\n",
    "y = enron1_train_y\n",
    "\n",
    "X_train_bn, X_test_bn, y_train_bn, y_test_bn = train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72ddfbb0-8274-47e7-955c-ddad4c92b76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.1, epochs:500 \n",
      "Accuracy: 0.84\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.87\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.01, epochs:500 \n",
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "\n",
    "lambda_reg = 0.1\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.01\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e51f306-f0db-4ebe-9cde-304aeddc2968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Selecting lambda = 0.5\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(enron1_train_bn, enron1_train_y, learning_rate, lambda_reg, num_iterations, enron1_test_bn, enron1_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb6dcef-08c2-4213-9439-2d49133eaee7",
   "metadata": {},
   "source": [
    "## Running the algorithm on enron2 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "554004dc-4341-461b-a70c-39d3b7aa502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enron2_train_bow\n",
    "y = enron2_train_y\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6710bd61-a221-4d99-bdcd-e7cfe0453794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.1, epochs:500 \n",
      "Accuracy: 0.91\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.92\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.01, epochs:500 \n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Run Logistic regression with different lambda values\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "\n",
    "lambda_reg = 0.1\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.01\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf6c18eb-c78a-4d4f-93d9-1ce761286d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Selecting lambda = 0.05\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(enron2_train_bow, enron2_train_y, learning_rate, lambda_reg, num_iterations, enron2_test_bow, enron2_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f65e06e-cbbb-4b63-bc19-df2d7322d2b8",
   "metadata": {},
   "source": [
    "## Running the algorithm on enron2 BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9358afe5-b1fb-48e8-ac9d-3b6db059cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enron2_train_bn\n",
    "y = enron2_train_y\n",
    "\n",
    "X_train_bn, X_test_bn, y_train_bn, y_test_bn = train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b80afb7b-07ac-4d39-adb5-a7dc5672cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.1, epochs:500 \n",
      "Accuracy: 0.81\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.83\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.01, epochs:500 \n",
      "Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "\n",
    "lambda_reg = 0.1\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.01\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "88be4ae3-9730-4125-9028-50fd6cabcf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Selecting lambda = 0.5\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(enron2_train_bn, enron2_train_y, learning_rate, lambda_reg, num_iterations, enron2_test_bn, enron2_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf06d86-f2e2-482d-a299-c8c25956d96b",
   "metadata": {},
   "source": [
    "## Running the algorithm on enron4 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e5f9962-c71c-42e6-8b57-769737ff081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enron4_train_bow\n",
    "y = enron4_train_y\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6df4b889-948d-47a3-8740-41869ec2fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.1, epochs:500 \n",
      "Accuracy: 0.93\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.92\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.01, epochs:500 \n",
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Run Logistic regression with different lambda values\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "\n",
    "lambda_reg = 0.1\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.01\n",
    "run_logistic_regression(X_train_bow, y_train_bow, learning_rate, lambda_reg, num_iterations, X_test_bow, y_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7b15cafa-0e1a-4dc6-a3bc-d0ff62050320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.01, epochs:500 \n",
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Selecting lambda = 0.01\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "lambda_reg = 0.01\n",
    "run_logistic_regression(enron4_train_bow, enron4_train_y, learning_rate, lambda_reg, num_iterations, enron4_test_bow, enron4_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a83793-fc6a-473a-ac81-badafaf90115",
   "metadata": {},
   "source": [
    "## Running the algorithm on enron4 BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "63a1fddf-7af9-4547-90a3-c08c244ddbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enron2_train_bn\n",
    "y = enron2_train_y\n",
    "\n",
    "X_train_bn, X_test_bn, y_train_bn, y_test_bn = train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fa31d7c5-4029-4d44-9195-40467164d654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.1, epochs:500 \n",
      "Accuracy: 0.86\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.05, epochs:500 \n",
      "Accuracy: 0.86\n",
      "\n",
      "\n",
      "Hyperparamters: learning_rate: 0.01, lambda:0.01, epochs:500 \n",
      "Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "\n",
    "lambda_reg = 0.1\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.05\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "lambda_reg = 0.01\n",
    "run_logistic_regression(X_train_bn, y_train_bn, learning_rate, lambda_reg, num_iterations, X_test_bn, y_test_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "affd69ae-19e8-44be-93ef-3157d8a32e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparamters: learning_rate: 0.01, lambda:0.01, epochs:500 \n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Selecting lambda = 0.01\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 500\n",
    "lambda_reg = 0.01\n",
    "run_logistic_regression(enron4_train_bn, enron4_train_y, learning_rate, lambda_reg, num_iterations, enron4_test_bn, enron4_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10a615-52b7-4f34-a28d-68a911feecad",
   "metadata": {},
   "source": [
    "# 4. SGDClassifier algorithm with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eddc2ab2-a0f4-4e16-a17d-c1c7df2512c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize SGDClassifier and GridSearchCV\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'loss': ['log_loss', 'hinge', 'modified_huber'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [1e-5, 1e-4, 1e-3],\n",
    "    'learning_rate': ['optimal', 'adaptive'],\n",
    "    'eta0': [0.1, 0.01, 0.001],\n",
    "    'max_iter': [500],\n",
    "    'tol': [1e-3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=sgd,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    n_jobs= -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0b5d993e-4e26-468f-997e-8e1549befc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that runs SGD on data in params\n",
    "def run_SGD_algorithm(X_train, y_train, X_test, y_test):\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best params found: {grid_search.best_params_}\")\n",
    "    print(\"\\n\")\n",
    "    best_sgd = grid_search.best_estimator_\n",
    "    y_pred = best_sgd.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Classification report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282891ac-5c28-4fd1-8de1-a109d01294d3",
   "metadata": {},
   "source": [
    "## Running algorithm on enron1 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6fd542c1-dc8d-43a1-be04-d4b33a36d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params found: {'alpha': 0.0001, 'eta0': 0.001, 'learning_rate': 'adaptive', 'loss': 'modified_huber', 'max_iter': 500, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "\n",
      "Model accuracy: 0.96\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       307\n",
      "           1       0.90      0.97      0.94       149\n",
      "\n",
      "    accuracy                           0.96       456\n",
      "   macro avg       0.94      0.96      0.95       456\n",
      "weighted avg       0.96      0.96      0.96       456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_SGD_algorithm(enron1_train_bow, enron1_train_y, enron1_test_bow, enron1_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f76dc7-2f28-4b2c-bc15-4ed18b35b62a",
   "metadata": {},
   "source": [
    "## Running algorithm on enron1 BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8c2db8f0-fb48-4626-98a0-70156a80e46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params found: {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss', 'max_iter': 500, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "\n",
      "Model accuracy: 0.96\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       307\n",
      "           1       0.92      0.96      0.94       149\n",
      "\n",
      "    accuracy                           0.96       456\n",
      "   macro avg       0.95      0.96      0.96       456\n",
      "weighted avg       0.96      0.96      0.96       456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_SGD_algorithm(enron1_train_bn, enron1_train_y, enron1_test_bn, enron1_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d74564-06eb-403a-8191-8823235ad428",
   "metadata": {},
   "source": [
    "## Running algorithm on enron2 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "caeea4b9-b182-46e6-b323-b5790603d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params found: {'alpha': 1e-05, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss', 'max_iter': 500, 'penalty': 'l2', 'tol': 0.001}\n",
      "\n",
      "\n",
      "Model accuracy: 0.94\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       348\n",
      "           1       0.92      0.87      0.89       130\n",
      "\n",
      "    accuracy                           0.94       478\n",
      "   macro avg       0.94      0.92      0.93       478\n",
      "weighted avg       0.94      0.94      0.94       478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_SGD_algorithm(enron2_train_bow, enron2_train_y, enron2_test_bow, enron2_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f9e1f-04b1-4e0b-8063-4ddcaea73d10",
   "metadata": {},
   "source": [
    "## Running algorithm on enron2 BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "90795bbb-cc68-4454-ace8-4a4e6087b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params found: {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'log_loss', 'max_iter': 500, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\n",
      "\n",
      "Model accuracy: 0.95\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       348\n",
      "           1       0.91      0.89      0.90       130\n",
      "\n",
      "    accuracy                           0.95       478\n",
      "   macro avg       0.94      0.93      0.93       478\n",
      "weighted avg       0.95      0.95      0.95       478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_SGD_algorithm(enron2_train_bn, enron2_train_y, enron2_test_bn, enron2_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3260f15d-aa37-4ab7-a04c-a0cb5a041a84",
   "metadata": {},
   "source": [
    "## Running algorithm on enron4 BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "23e4912d-df14-4e04-a749-13c52b9d4170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params found: {'alpha': 1e-05, 'eta0': 0.001, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 500, 'penalty': 'l1', 'tol': 0.001}\n",
      "\n",
      "\n",
      "Model accuracy: 0.97\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       152\n",
      "           1       0.97      0.98      0.98       391\n",
      "\n",
      "    accuracy                           0.97       543\n",
      "   macro avg       0.97      0.96      0.96       543\n",
      "weighted avg       0.97      0.97      0.97       543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_SGD_algorithm(enron4_train_bow, enron4_train_y, enron4_test_bow, enron4_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887b486-4b6a-48fb-89cc-6a4310e3fa35",
   "metadata": {},
   "source": [
    "## Running algorithm on enron4 BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "23ca1d63-8819-4854-be73-fe16f7c76ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params found: {'alpha': 1e-05, 'eta0': 0.01, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 500, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\n",
      "\n",
      "Model accuracy: 0.97\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93       152\n",
      "           1       0.95      1.00      0.98       391\n",
      "\n",
      "    accuracy                           0.97       543\n",
      "   macro avg       0.98      0.94      0.95       543\n",
      "weighted avg       0.97      0.97      0.96       543\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_SGD_algorithm(enron4_train_bn, enron4_train_y, enron4_test_bn, enron4_test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
